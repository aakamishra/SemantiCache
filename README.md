# SemantiCache - for weakly-supervised model length prediction 

## Aakash Mishra (aamishra@stanford.edu)


If you find this repository useful, please consider citing the following paper which this repository is based on. 

```
@inproceedings{aiops2024qiu,
  author  = {Qiu, Haoran and Mao, Weichao and Patke, Archit and Cui, Shengkun and Jha, Saurabh and Wang, Chen and Franke, Hubertus and Kalbarczyk, Zbigniew T. and Ba\c{s}ar, Tamer and Iyer, Ravishankar K.},
  title   = {Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction},
  year    = {2024},
  pages = {1--7},
  publisher = {Association for Computing Machinery},
  volume = {5},
  address = {San Diego, CA, USA},
  booktitle = {The 5th International Workshop on Cloud Intelligence / AIOps at ASPLOS 2024},
}
```

## Getting Support

- Haoran Qiu (haoranq4@illinois.edu)
- Create a GitHub [issue](https://github.com/James-QiuHaoran/LLM-serving-with-proxy-models/issues).
